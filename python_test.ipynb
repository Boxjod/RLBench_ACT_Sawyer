{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取位置编码\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "action = [6.426e-1, -2.180e-1, 9.110e-2, -6.169e-5, 9.850e-1, 4.307e-4, 1.727e-1, 1.000e+0]\n",
    "target_qpos_list = []\n",
    "target_qpos_list.append(action)\n",
    "target_qpos_list.append(action)\n",
    "target_qpos_list.append(action)\n",
    "target_qpos_list.append(action)\n",
    "\n",
    "print(np.shape(target_qpos_list))\n",
    "\n",
    "position = target_qpos_list[3][:7]\n",
    "\n",
    "# 在这个位置周围随机生成一个点\n",
    "print(position)\n",
    "\n",
    "# 根据elem的数量级决定 随机加减数量\n",
    "\n",
    "# 又机器人模型决定单个步骤是否完成\n",
    "\n",
    "for i in range(10):\n",
    "  position = [elem *(1 + (np.random.randint(100) - 50)/1000) for elem in position]\n",
    "  print(position)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逻辑比较\n",
    "a = True\n",
    "b = True\n",
    "c = False\n",
    "\n",
    "if a and (b or c):\n",
    "  print(\"success\")\n",
    "else:\n",
    "  print(\"fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10%5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 3)\n",
      "(5, 4, 3, 2)\n",
      "(5, 4, 3, 3)\n",
      "(5, 4, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "aaa = np.array([[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]]])\n",
    "\n",
    "\n",
    "# bbb = np.expand_dims(aaa,3).repeat(3,axis=3)\n",
    "\n",
    "# 三种维度的距离？？统一维度有一点浪费存储空间\n",
    "# bbb = np.expand_dims(aaa,3)\n",
    "\n",
    "aaa = aaa/30\n",
    "print(np.shape(aaa))\n",
    "\n",
    "bbb1 = np.clip((aaa * 255. * 1.0), 0, 255).astype(np.uint8)\n",
    "bbb2 = np.clip((aaa * 255. * 5.0), 0, 255).astype(np.uint8)\n",
    "bbb3 = np.clip((aaa * 255. * 10.0 ), 0, 255).astype(np.uint8)\n",
    "\n",
    "ccc = np.stack((bbb1,bbb2),axis=3)\n",
    "print(np.shape(ccc))\n",
    "bbb4 = np.expand_dims(bbb3,axis=3)\n",
    "ccc = np.append(ccc,bbb4,axis=3)\n",
    "print(np.shape(ccc))\n",
    "ddd = np.append(ccc,bbb4,axis=3)\n",
    "print(np.shape(ddd))\n",
    "# print(ccc)\n",
    "# bbb = np.append(aaa,aaa)\n",
    "\n",
    "# print(np.shape(bbb))\n",
    "\n",
    "# print(ccc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三原色 降为压缩\n",
    "import numpy as np\n",
    "\n",
    "rgb = np.array([[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]],[[1,2,3],[1,2,3],[1,2,3],[1,2,3]]])\n",
    "\n",
    "print(np.shape(rgb))\n",
    "\n",
    "# red = rgb[:,:,0]\n",
    "\n",
    "# color = np.sum(rgb,2)\n",
    "# color = [rgb[0]+rgb[1], rgb[1]+rgb[2]]\n",
    "\n",
    "print(np.shape(red))\n",
    "print(red)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "ext = \"oepn,steps(5)\"\n",
    "if len(ext) > 0 and 'steps(' in ext:\n",
    "  start_of_bracket = ext.index('steps(') + 6\n",
    "  steps_len = ext[start_of_bracket] \n",
    "  print(steps_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "for i in range(0, num_epoch):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "ext = \"close_gripper();ignore_collisions;steps(3);close_gripper();\"\n",
    "if len(ext) > 0 and 'steps(' in ext:\n",
    "  left = ext.index('steps(')+6\n",
    "  right = ext[left:].index(')')\n",
    "  \n",
    "  print(ext[left:left+right])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wrist']\n"
     ]
    }
   ],
   "source": [
    "cam_names = [['wrist'], ['wrist', 'head']] \n",
    "print(cam_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_epochs': 222, 'policy': {'num_epochs': 1112}}\n"
     ]
    }
   ],
   "source": [
    "policy = {\n",
    "        'num_epochs': 111\n",
    "    }\n",
    "config = {\n",
    "        'num_epochs': 111,\n",
    "        'policy': policy\n",
    "    }\n",
    "config['num_epochs']=222\n",
    "config['policy']['num_epochs']=1112\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "task_steps = ['sorting_program21', 'sorting_program22']\n",
    "print(len(task_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=1\n",
      "x=2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = 1 \n",
    "\n",
    "print(f'x={x}')\n",
    "\n",
    "def function(x):\n",
    "  x = x + 1\n",
    "  print(f'x={x}')\n",
    "\n",
    "function(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'the 1': 1}\n",
      "4\n",
      "{'the 1': 1, 'the 3': 3}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "conmmand_len = 2\n",
    "dict = {}\n",
    "\n",
    "for i in range(1, 2*conmmand_len, 2):\n",
    "  print(i+1)\n",
    "  dict[f\"the {i}\"] = i\n",
    "  print(dict)\n",
    "  \n",
    "  # print(np.random.randint(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> 1\n",
      "<class 'int'> 12\n",
      "<class 'int'> 123\n"
     ]
    }
   ],
   "source": [
    "# import string\n",
    "\n",
    "ssss = \"\"\n",
    "num_len = 4\n",
    "# ssss = [(ssss + str(i) ) for i in range(1, num_len)]\n",
    "# print(ssss)\n",
    "\n",
    "for i in range(1,num_len):\n",
    "  ssss = ssss + str(i)\n",
    "  \n",
    "  print(type(int(ssss)),ssss)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put the red target to the red box\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = \"/home/boxjod/Gym/RLBench/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04\"\n",
    "# os.environ['LD_LIBRARY_PATH'] = \"$COPPELIASIM_ROOT:$LD_LIBRARY_PATH\"\n",
    "# os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = \"$COPPELIASIM_ROOT\"\n",
    "\n",
    "# x = 99\n",
    "\n",
    "# print(x.isalnum())\n",
    "\n",
    "color_name = 'red'\n",
    "\n",
    "print('put the %s target to the %s box' % (color_name ,color_name) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 4. 4. 4. 4. 4. 4. 4.]\n",
      " [3. 3. 3. 3. 3. 3. 3. 3.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 历史记录当中有空的，这样处理\n",
    "import numpy as np\n",
    "num_queries = 10\n",
    "\n",
    "pos_initial = np.array([[0,0,0,0,0,0,0,0]])\n",
    "\n",
    "for idx in range(1,5):\n",
    "  pos_initial = np.append(pos_initial,[[idx,idx,idx,idx,idx,idx,idx,idx]], axis=0)\n",
    "\n",
    "original_action_shape = pos_initial.shape #(32,8)  # np.zeros((32,8))\n",
    "action_len = original_action_shape[0]\n",
    "\n",
    "action_len = min(action_len, num_queries)#################\n",
    "\n",
    "qpos_history = np.zeros((num_queries,) + original_action_shape[1:], dtype=np.float32)\n",
    "\n",
    "pos_initial = pos_initial[::-1]\n",
    "\n",
    "qpos_history[:action_len] = pos_initial[:action_len]\n",
    "\n",
    "print(qpos_history)\n",
    "index_refresh = 0\n",
    "\n",
    "# eval 的时候新的history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [11.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [10.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 9.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 8.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 7.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 6.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 5.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 4.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 3.  2.  2.  2.  2.  2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# 往前面加\n",
    "index_refresh = index_refresh + 1\n",
    "action = np.array([index_refresh,2,2,2,2,2,2,2])\n",
    "qpos_history = np.insert(qpos_history,0,action, axis=0)[:num_queries]\n",
    "\n",
    "# qpos_history = np.append(qpos_history[1:], action, axis=0)\n",
    "\n",
    "print(qpos_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "10\n",
      "[8, 9, 0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "end_ts = 32\n",
    "start_ts = 17\n",
    "num_queries = 10\n",
    "\n",
    "root = dict()\n",
    "root['/action'] = [1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0,1,2]\n",
    "\n",
    "action_len = end_ts - start_ts + 1 \n",
    "print(action_len)\n",
    "if action_len < num_queries:\n",
    "    action = root['/action'][start_ts : end_ts + 1]\n",
    "else:\n",
    "    action = root['/action'][start_ts : start_ts + num_queries]\n",
    "\n",
    "print(len(action))\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "[7, 8, 9, 0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "end_ts = 32\n",
    "start_ts = 16\n",
    "num_queries = 10\n",
    "\n",
    "root = dict()\n",
    "root['/action'] = [1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0,1,2]\n",
    "\n",
    "history_action_len = start_ts + 1\n",
    "print(action_len)\n",
    "print()\n",
    "\n",
    "if history_action_len < num_queries:\n",
    "    history_action = root['/action'][0 : start_ts + 1]\n",
    "    for history_idx in range(start_ts + 1):\n",
    "        print(history_idx)\n",
    "else:\n",
    "    history_action = root['/action'][start_ts - num_queries : start_ts]\n",
    "    for history_idx in range(start_ts - num_queries, start_ts + 1):\n",
    "        print(history_idx)\n",
    "\n",
    "print(history_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m index_refresh \u001b[38;5;241m=\u001b[39m index_refresh \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[index_refresh,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m]])\n\u001b[0;32m----> 4\u001b[0m qpos_history \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqpos_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(qpos_history)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:5499\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5497\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5498\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "# 往后面加\n",
    "index_refresh = index_refresh + 1\n",
    "action = np.array([[index_refresh,2,2,2,2,2,2,2]])\n",
    "qpos_history = np.append(qpos_history[1:], action, axis=0)\n",
    "print(qpos_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action=array([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "action=tensor([1., 2., 3., 4., 5., 6., 7., 8.])\n",
      "history_action_embed=tensor([[[1., 2., 3., 4., 5., 6., 7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "action = np.array([1,2,3,4,5,6,7,8])\n",
    "print(f\"{action=}\")\n",
    "\n",
    "action = torch.from_numpy(action).float()\n",
    "print(f\"{action=}\")\n",
    "\n",
    "history_action_embed = torch.unsqueeze(action, axis=0).repeat(1, 1,1)\n",
    "print(f\"{history_action_embed=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 模拟图像 数据集\n",
    "image_data = {\n",
    "        '/observations/images/wrist': [],\n",
    "    }\n",
    "# image_data['wrist'] = np.ones([120,160])\n",
    "\n",
    "image = np.ones([120,160,3])\n",
    "\n",
    "for idx in range(32):\n",
    "  image_data['/observations/images/wrist'].append(image)\n",
    "\n",
    "# print(np.shape(image_data))\n",
    "# print(image_data['/observations/images/wrist'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_action\n",
    "start_ts = 17\n",
    "history_action_len = start_ts + 1\n",
    "max_len = 32\n",
    "\n",
    "camera_names = ['wrist']\n",
    "dataset_dir = \"sawyer\"\n",
    "\n",
    "# 加入历史图像\n",
    "history_images = []\n",
    "history_image_dict = dict()\n",
    "for history_idx in range(start_ts + 1):\n",
    "    \n",
    "    for cam_name in camera_names:\n",
    "        history_image_dict[cam_name] = image_data[f'/observations/images/{cam_name}'][history_idx]\n",
    "    \n",
    "    # history_images = history_images.append(history_image_dict)\n",
    "    # 两个数据类型不一样的时候会出现AttributeError: 'NoneType' object has no attribute 'append'\n",
    "    history_images.append(history_image_dict) # 直接这样使用append才是正确的\n",
    "    \n",
    "# print(f\"{np.shape(history_images[0])=}\")\n",
    "# print(history_images[0]['wrist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120, 160, 3)\n",
      "(18, 1, 120, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_all_cam_images = []\n",
    "for history_idx in range(history_action_len):\n",
    "    all_history_cam_images = []\n",
    "    \n",
    "    for cam_name in camera_names: \n",
    "        all_history_cam_images.append(history_images[history_idx][cam_name])\n",
    "\n",
    "    all_history_cam_images = np.stack(all_history_cam_images, axis=0)\n",
    "    \n",
    "    history_all_cam_images.append(all_history_cam_images)\n",
    "    \n",
    "print(np.shape(all_history_cam_images))\n",
    "print(np.shape(history_all_cam_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n",
      "(10, 1, 120, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# 这里输出要 padded 到32，不够的图像补充0\n",
    "\n",
    "pos_initial = np.array([[9,9,9,9,9,9,9,9], [9,9,9,9,9,9,9,9], [9,9,9,9,9,9,9,9], [9,9,9,9,9,9,9,9], ])\n",
    "\n",
    "original_action_shape = pos_initial.shape #(32,8)  # np.zeros((32,8))\n",
    "action_len = original_action_shape[0]\n",
    "print(original_action_shape)\n",
    "\n",
    "history_action_len = 10\n",
    "\n",
    "original_images_shape = np.shape(history_all_cam_images)\n",
    "padded_history_images = np.zeros((history_action_len,) + original_images_shape[1:], dtype=np.float32)\n",
    "\n",
    "padded_history_images = padded_history_images[::-1]\n",
    "\n",
    "padded_history_images[:history_action_len] = history_all_cam_images[:history_action_len] # 往前面添加historyaction\n",
    "\n",
    "print(np.shape(padded_history_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90])\n",
      "torch.Size([1, 90])\n",
      "torch.Size([1, 90])\n"
     ]
    }
   ],
   "source": [
    "ispad = np.zeros(90)\n",
    "ispad = torch.from_numpy(ispad)\n",
    "bs = 1\n",
    "print(ispad.shape)\n",
    "ispad = torch.unsqueeze(ispad, axis=0).repeat(bs, 1) # (1, 90)\n",
    "print(ispad.shape)\n",
    "ispad = ispad[:,]\n",
    "print(ispad.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 1, 120, 160, 3)\n",
      "torch.Size([18, 1, 3, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Constructing the observations\n",
    "history_all_cam_images = np.array(history_all_cam_images)\n",
    "print(np.shape(history_all_cam_images))\n",
    "\n",
    "# for history_idx in range(history_action_len):\n",
    "\n",
    "history_images_data = torch.from_numpy(history_all_cam_images)\n",
    "history_images_data = torch.einsum('q k h w c -> q k c h w', history_images_data) # 多一个querry，chunking的队列长度\n",
    "\n",
    "print(np.shape(history_images_data))\n",
    "\n",
    "# print(history_images_data)\n",
    "\n",
    "# 然后返回出去，传到模型里面，在处理history_action的时候一起处理了，使用同一个backbone处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 3, 120, 160])\n",
      "torch.Size([10, 1, 3, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "# policy\n",
    "num_queries = 10\n",
    "\n",
    "\n",
    "is_training = True\n",
    "# train\n",
    "# history_images = history_images[:, :num_queries] # 前面那个是batch_size\n",
    "\n",
    "\n",
    "# eval\n",
    "if not is_training:\n",
    "  print(np.shape(history_images_data))\n",
    "  history_images = history_images_data[:num_queries]\n",
    "  print(np.shape(history_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练的时候：\n",
    "# 有batch_size\n",
    "\n",
    "# 又要扩一个维度的batch_size，训练模式的时候有自动的 batch_size\n",
    "if not is_training:\n",
    "  bs = 1\n",
    "  history_images = torch.unsqueeze(history_images, axis=0).repeat(bs, 1, 1, 1, 1, 1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10, 1, 3, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(history_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入进来的是 history_images， additional_all_history_cam_pos（num_queries，hidden_dim）\n",
    "\n",
    "# 使用backbone处理\n",
    "history_all_cam_src = []\n",
    "history_all_cam_pos = []\n",
    "\n",
    "for history_idx in range(history_action_len):\n",
    "  all_history_cam_features = []\n",
    "  all_history_cam_pos = []\n",
    "  for cam_id, cam_name in enumerate(self.camera_names): # 0 ‘wrist’\n",
    "    features, pos = self.backbones[cam_id](history_images[:,history_idx, cam_id]) # [batch_size, history_idx, cam_id, chanel, width, height]\n",
    "    features = features[0] # take the last layer feature [8, 1536, 4, 5]\n",
    "    pos = pos[0] # take the last layer pos [8, 1536, 4, 5]\n",
    "    all_history_cam_features.append(self.input_proj(features)) # 训练的时候[8, 1536, 4, 5] -> [8, 512, 4, 5] -> [1, 8, 512, 4, 5]\n",
    "    all_history_cam_pos.append(pos)  # pos的 shape 本来就是 512\n",
    "      \n",
    "  # fold camera dimension into width dimension\n",
    "  all_history_cam_src = torch.cat(all_history_cam_features, axis=3)  # [1, 8, 512, 4, 5] -> [8, 512, 4, 5], 把多张图片折叠到了 width 维度\n",
    "  all_history_cam_pos = torch.cat(all_history_cam_pos, axis=3) # [1, 8, 512, 4, 5] -> [8, 512, 4, 5] 把多张图片折叠到了 width 维度\n",
    "  \n",
    "  # 如何处理成Transformer Encoder的输入格式\n",
    "  bs, c, h, w = all_history_cam_src.shape\n",
    "  all_history_cam_src = all_history_cam_src.flatten(2).permute(2, 0, 1) # (seq*2 ,bs )\n",
    "  all_history_cam_pos = all_history_cam_pos.flatten(2).permute(2, 0, 1).repeat(1, bs, 1) # 图像的编码，有几个图像就加了几个的，不用管它\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "  # query_embed 是一个权重 self.query_embed.weight\n",
    "  # 这个 history_action 有\n",
    "  \n",
    "  query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
    "  \n",
    "  # mask = mask.flatten(1)\n",
    "  additional_pos_embed = additional_pos_embed.unsqueeze(1).repeat(1, bs, 1) # seq, bs, dim \n",
    "  pos_embed = torch.cat([additional_pos_embed, pos_embed], axis=0)\n",
    "  \n",
    "  addition_input = torch.stack([latent_input, proprio_input_qpos, command_embedding], axis=0)\n",
    "  src = torch.cat([addition_input, src], axis=0)\n",
    "  \n",
    "  self.encoder(src, src_key_padding_mask=mask, pos=pos_embed)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  history_all_cam_src.append(all_history_cam_src) #  [1, 8, 512, 4, 5]\n",
    "  history_all_cam_pos.append(all_history_cam_pos)\n",
    "\n",
    "\n",
    "# 然后获得了\n",
    "# history_all_cam_src = ()\n",
    "# history_all_cam_pos = ()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 图像特征、图像特征位置编码、风格变量Z、joints映射后的，以及position embeddings (fixed)，权重丢进去，在训练的时候训练好的？？\n",
    "hs = self.transformer(src, None, self.query_embed.weight, pos, latent_input, proprio_input_qpos, proprio_input_gpos, self.additional_pos_embed.weight, command_embedding=command_embedding_to_append)[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 4, 5])\n",
      "torch.Size([8, 1, 512])\n",
      "torch.Size([8, 2, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "batch_size = 8\n",
    "all_history_cam_src = torch.randn(batch_size, 512, 4, 5)\n",
    "print(all_history_cam_src.shape)\n",
    "\n",
    "\n",
    "all_history_cam_src = all_history_cam_src.flatten(2) # (bs, 512, 4, 5) -> 4x5=20 (bs, 512, 20)\n",
    "all_history_cam_src = torch.mean(all_history_cam_src, dim=2).unsqueeze(1)# (bs, 512, 20) -> (bs, 512)\n",
    "\n",
    "print(all_history_cam_src.shape)\n",
    "\n",
    "# history_all_cam_src = torch.empty( dtype=torch.float32)\n",
    "# history_all_cam_src = torch.cat([all_history_cam_src, all_history_cam_src], axis=1)\n",
    "\n",
    "for ids in range(10):\n",
    "  history_all_cam_src = torch.cat([all_history_cam_src, all_history_cam_src], axis=1)\n",
    "  \n",
    "print(history_all_cam_src.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 初始化三个 tensor\n",
    "A=torch.ones(2,3)    #2x3的张量（矩阵）                                     \n",
    "# tensor([[ 1.,  1.,  1.],\n",
    "#         [ 1.,  1.,  1.]])\n",
    "B=2*torch.ones(4,3)  #4x3的张量（矩阵）                                    \n",
    "# tensor([[ 2.,  2.,  2.],\n",
    "#         [ 2.,  2.,  2.],\n",
    "#         [ 2.,  2.,  2.],\n",
    "#         [ 2.,  2.,  2.]])\n",
    "# D=2*torch.ones(2,4)\t # 2x4的张量（矩阵）\n",
    "# tensor([[ 2.,  2.,  2., 2.],\n",
    "#         [ 2.,  2.,  2., 2.],\n",
    "\n",
    "\n",
    "# 按维数0（行）拼接 A 和 B\n",
    "C=torch.cat((A,B),0) \n",
    "# tensor([[ 1.,  1.,  1.],\n",
    "#          [ 1.,  1.,  1.],\n",
    "#          [ 2.,  2.,  2.],\n",
    "#          [ 2.,  2.,  2.],\n",
    "#          [ 2.,  2.,  2.],\n",
    "#          [ 2.,  2.,  2.]])\n",
    "print(C.shape)\n",
    "# torch.Size([6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(history_image_feature)=(32, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_timesteps = 32\n",
    "hidden_dim = 512\n",
    "history_image_feature = np.zeros((max_timesteps,) + (hidden_dim,), dtype=np.float32)\n",
    "\n",
    "print(f\"{np.shape(history_image_feature)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "(2, 512)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "max_timesteps = 10\n",
    "hidden_dim = 512\n",
    "\n",
    "image_src = torch.rand(1,512)\n",
    "# print(image_src)\n",
    "image_pos = torch.rand(1,512)\n",
    "\n",
    "encode_history_image_pos = [image_src, image_pos]\n",
    "\n",
    "print(np.shape(encode_history_image_pos[0]))\n",
    "history_image_feature = np.zeros((2,max_timesteps) + (512,), dtype=np.float32)\n",
    "\n",
    "print(np.shape(history_image_feature[:,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10, 512)\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.84650916\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n",
      "0.5960442\n"
     ]
    }
   ],
   "source": [
    "history_image_feature[0] = np.insert(history_image_feature[0], 0, encode_history_image_pos[0], axis=0)[:max_timesteps]\n",
    "history_image_feature[1] = np.insert(history_image_feature[1], 0, encode_history_image_pos[1], axis=0)[:max_timesteps]\n",
    "\n",
    "print(np.shape(history_image_feature))\n",
    "for idx in range(max_timesteps):\n",
    "  print(history_image_feature[0][idx][0])\n",
    "for idx in range(max_timesteps):\n",
    "  print(history_image_feature[1][idx][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
